---
title: "Estimation of VAFs of tumors across multiple timepoints for the PBTA Cohort"
author: 'Antonia Chroni <chronia@chop.edu> and Jo Lynne Rokita <rokita@chop.edu> for D3B'
date: "2023"
output:
  html_notebook:
    toc: TRUE
    toc_float: TRUE
---


#### Tumor evolution project 

# Background
We are investigating the change of VAFs across multiple timepoints in the PBTA cohort.

### Data used 
In this notebook, we are looking into the v12 histologies file (last updates on May 1st, 2023) and subset to the PBTA cohort.
We use the output files from the "analyses/sample-distribution-analysis/results".

### Method used 


### Usage

This notebook is intended to be run via the command line from the top directory of the repository as follows:

```
Rscript -e "rmarkdown::render('01-process-data.Rmd', clean = TRUE)"
```

# Set up

```{r load-library}
suppressPackageStartupMessages({
  library(tidyverse)
  library(data.table)
  library(flextable)
  library(plyr)
  library(ggplot2)
  library(ggpubr)
  library(ggrepel)
})
```

## Directories and File Inputs/Outputs

```{r set-dir-and-file-names}
# Detect the ".git" folder -- this will be in the project root directory.
# Use this as the root directory to ensure proper sourcing of functions no
# matter where this is called from
root_dir <- rprojroot::find_root(rprojroot::has_dir(".git"))

data_dir <- file.path(root_dir, "data")
# Inputs
v12 <- file.path(data_dir, "histologies.tsv")
maf <- file.path(data_dir, "snv-consensus-plus-hotspots.maf.tsv.gz")


# create analysis_dir
analysis_dir <- file.path(root_dir, "analyses", "create-corplots")

# File path to input directory
input_dir <- file.path(analysis_dir, "input")

# tmb file
tmb <- file.path(input_dir, "snv-mutation-tmb-coding.tsv")

# The following files were generated from the add-sample-distribution analysis
files_dir <- file.path(root_dir, "analyses", "sample-distribution-analysis", "results")
genomic_assays_matched_time_points <- file.path(files_dir, "genomic_assays_matched_time_points.tsv")


# File path to results directory
results_dir <-
  file.path(analysis_dir, "results")
if (!dir.exists(results_dir)) {
  dir.create(results_dir)
}


# File path to scratch dir to save large files not needed at later stages in the analysis
scratch <-
  file.path(root_dir, "scratch")
if (!dir.exists(scratch)) {
  dir.create(scratch)
}
```

## Load and Process data
We will also Calculate VAFs per each Kids_First_Biospecimen_ID.

```{r load-inputs-please-wait}
# pbta cohort
pbta <- readr::read_tsv(v12, guess_max = 100000, show_col_types = FALSE) %>%
  filter(cohort == "PBTA",
         !is.na(pathology_diagnosis),
         !composition %in% c("Derived Cell Line", "PDX"),
         !experimental_strategy %in% c("Methylation", "Targeted Sequencing")) 

## Read MAF file
snv <- data.table::fread(maf, data.table = F) %>%
  filter(Tumor_Sample_Barcode %in% pbta$Kids_First_Biospecimen_ID) %>%
  dplyr::rename(Kids_First_Biospecimen_ID = Tumor_Sample_Barcode) %>% # change the column name of the biospecimen column to match the column name from the histologies files
  dplyr::mutate(VAF = t_alt_count / (t_ref_count + t_alt_count)) %>% # calculate VAF
  select(Kids_First_Biospecimen_ID, Hugo_Symbol, Chromosome, Start_Position, Variant_Classification, VAF, HGVSc, HGVSp, HGVSp_Short) 

## Read in genomic_assays_matched_time_points file and get the list of patients
genomic_assays_matched_time_points_list <- readr::read_tsv(genomic_assays_matched_time_points, guess_max = 100000, show_col_types = FALSE) %>%
                                      subset(select = c("Kids_First_Participant_ID", "descriptors"))
  
# Read file with TMB information
tmb <- readr::read_tsv(tmb, guess_max = 100000, show_col_types = FALSE)
```

# Select patients with genomic assays

```{r echo=TRUE}
# We will look only into samples with genomic assays
# We will use the list fo the patients from the "genomic_assays_matched_time_points_list" and merge to the pbta table
# We need to count how many tumor samples we have per patient/time point, if any
# We need to create a column to do that: match_id_multiple_samples
genomic_assays_matched_time_points_list_merge <- genomic_assays_matched_time_points_list %>% 
  left_join(pbta, by=c('Kids_First_Participant_ID')) %>%
  filter(!(experimental_strategy == "RNA-Seq")) %>%
  mutate(match_id_multiple_samples = paste(Kids_First_Participant_ID, sample_id, composition, sep = "_")) %>%
  mutate(tumor_descriptor = case_when(grepl("Primary Tumor", tumor_descriptor) ~ "Diagnosis",
                                 grepl("Initial CNS Tumor", tumor_descriptor) ~ "Diagnosis",
                                 grepl('Progressive Disease Post-Mortem', tumor_descriptor) ~ 'Deceased', 
                                 TRUE ~ tumor_descriptor)) %>%
  mutate(Deceased = case_when(grepl("Deceased", descriptors) ~ "Deceased")) %>%
  filter(Deceased == "Deceased") %>%
  write_tsv(file.path(results_dir, "genomic_assays_matched_time_points_list_merge.tsv"))
```

# Autopsy samples 
We will focus on patient cases containing autopsy samples and save these maf files separately.
We will do this for different pairs.


```{r maf_files_Deceased}
#let us filter by Deceased samples
maf_files_Deceased <- genomic_assays_matched_time_points_list_merge %>% 
  left_join(snv, by=c('Kids_First_Biospecimen_ID')) %>%
  filter(!is.na(Kids_First_Participant_ID)) %>%
  filter(!is.na(VAF)) %>%
  write_tsv(file.path(scratch, "maf_files_Deceased.tsv"))
```

## Let's save the maf files per each category

```{r save-maf-files}
##########################################################################################
# Storing all Dx-Deceased Sample pairs in a list so each file can be processed iteratively
scratch_Dx_Dec <-
  file.path(scratch, "Dx_Dec")
if (!dir.exists(scratch_Dx_Dec)) {
  dir.create(scratch_Dx_Dec)
}

setwd(scratch_Dx_Dec)
data <- maf_files_Deceased %>% 
  mutate(data = case_when(grepl("Deceased, Diagnosis", descriptors) ~ "Dx_Dec")) %>%
  filter(data == "Dx_Dec")

# we will split maf data by the "Kids_First_Participant_ID" column
data %>% 
  group_split(Kids_First_Participant_ID) %>% 
  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))


##########################################################################################
# Storing all Pro_Dec Sample pairs in a list so each file can be processed iteratively
scratch_Pro_Dec <-
  file.path(scratch, "Pro_Dec")
if (!dir.exists(scratch_Pro_Dec)) {
  dir.create(scratch_Pro_Dec)
}

setwd(scratch_Pro_Dec)
data <- maf_files_Deceased %>% 
  filter(descriptors %in% c("Deceased, Progressive", "Deceased, Progressive, Progressive"))

# we will split maf data by the "Kids_First_Participant_ID" column
data %>% 
  group_split(Kids_First_Participant_ID) %>% 
  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))


##########################################################################################
# Storing all Deceased, Recurrence Sample pairs in a list so each file can be processed iteratively
scratch_Rec_Dec <-
  file.path(scratch, "Rec_Dec")
if (!dir.exists(scratch_Rec_Dec)) {
  dir.create(scratch_Rec_Dec)
}

setwd(scratch_Rec_Dec)
data <- maf_files_Deceased %>% 
  filter(descriptors == "Deceased, Recurrence")

# we will split maf data by the "Kids_First_Participant_ID" column
data %>% 
  group_split(Kids_First_Participant_ID) %>% 
  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))

##########################################################################################  
# Storing all Dx_Pro_Dec Sample pairs in a list so each file can be processed iteratively
scratch_Dx_Pro_Dec <-
  file.path(scratch, "Dx_Pro_Dec")
if (!dir.exists(scratch_Dx_Pro_Dec)) {
  dir.create(scratch_Dx_Pro_Dec)
}

setwd(scratch_Dx_Pro_Dec)
data <- maf_files_Deceased %>% 
        mutate(data = case_when(grepl("Deceased, Diagnosis, Diagnosis, Progressive, Progressive", descriptors) ~ "Dx_Pro_Dec")) %>%
 filter(data == "Dx_Pro_Dec")

# we will split maf data by the "Kids_First_Participant_ID" column
data %>% 
  group_split(Kids_First_Participant_ID) %>% 
  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))


##########################################################################################
# Storing all Dx_Rec_Dec Sample pairs in a list so each file can be processed iteratively
scratch_Dx_Rec_Dec <-
  file.path(scratch, "Dx_Rec_Dec")
if (!dir.exists(scratch_Dx_Rec_Dec)) {
  dir.create(scratch_Dx_Rec_Dec)
}

setwd(scratch_Dx_Rec_Dec)
data <- maf_files_Deceased %>% 
  mutate(data = case_when(grepl("Deceased, Diagnosis, Recurrence", descriptors) ~ "Dx_Rec_Dec")) %>%
  filter(data == "Dx_Rec_Dec")

# we will split maf data by the "Kids_First_Participant_ID" column
data %>% 
  group_split(Kids_First_Participant_ID) %>% 
  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))

##########################################################################################
# Storing all Pro_Rec_Dec Sample pairs in a list so each file can be processed iteratively
scratch_Pro_Rec_Dec <-
  file.path(scratch, "Pro_Rec_Dec")
if (!dir.exists(scratch_Pro_Rec_Dec)) {
  dir.create(scratch_Pro_Rec_Dec)
}

setwd(scratch_Pro_Rec_Dec)
data <- maf_files_Deceased %>% 
 mutate(data = case_when(grepl("Deceased, Progressive, Recurrence", descriptors) ~ "Pro_Rec_Dec")) %>%
  filter(data == "Pro_Rec_Dec")

# we will split maf data by the "Kids_First_Participant_ID" column
data %>% 
  group_split(Kids_First_Participant_ID) %>% 
 walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))
##########################################################################################
# let's change back to the root_dir for the rest of the module
setwd(root_dir)
```


```{r echo=TRUE}
sessionInfo()
```
  