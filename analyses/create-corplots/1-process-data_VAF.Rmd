---
title: "Estimation of VAFs of tumors across multiple timepoints for the PBTA Cohort"
author: 'Antonia Chroni <chronia@chop.edu> and Jo Lynne Rokita <rokita@chop.edu> for D3B'
date: "2023"
output:
  html_notebook:
    toc: TRUE
    toc_float: TRUE
---


#### Tumor evolution project 

# Background
We are investigating the change of VAFs across multiple timepoints in the PBTA cohort.

### Data used 
In this notebook, we are looking into the v12 histologies file (last updates on May 1st, 2023) and subset to the PBTA cohort.
We use the output files from the "analyses/sample-distribution-analysis/results".

### Method used 


### Usage

This notebook is intended to be run via the command line from the top directory of the repository as follows:

```
Rscript -e "rmarkdown::render('analyses/create-corplots/1-process-data_VAF.Rmd', clean = TRUE)"
```

# Set up

```{r load-library}
suppressPackageStartupMessages({
  library(tidyverse)
  library(data.table)
  library(flextable)
  library(plyr)
  library(ggplot2)
  library(ggpubr)
  library(ggrepel)
})
```

## Directories and File Inputs/Outputs

```{r set-dir-and-file-names}
# Detect the ".git" folder -- this will be in the project root directory.
# Use this as the root directory to ensure proper sourcing of functions no
# matter where this is called from
root_dir <- rprojroot::find_root(rprojroot::has_dir(".git"))
# root_dir <- "/Users/chronia/CHOP/GitHub/pbta-tumor-evolution"
setwd(root_dir)

analysis_dir <- file.path(root_dir, "analyses", "create-corplots")

# File path to input directory
input_dir <-
  file.path(analysis_dir, "input")

# Inputs
input_snv <- file.path(root_dir, "data/snv-consensus-plus-hotspots.maf.tsv.gz")

# The following files were generated from the add-sample-distribution analysis
input_cohort_pbta <- file.path(input_dir, "pbta.tsv")
input_genomic_df_filter <- file.path(input_dir, "genomic_df_filter.tsv")

# File path to results directory
results_dir <-
  file.path(analysis_dir, "results")
if (!dir.exists(results_dir)) {
  dir.create(results_dir)
}

# File path to results directory
plots_dir <-
  file.path(analysis_dir, "plots")
if (!dir.exists(plots_dir)) {
  dir.create(plots_dir)
}

source(paste0(root_dir, "/figures/theme.R"))
```

## Load data
```{r load-inputs-please-wait}
# Inputs
## Read MAF file
snv <- data.table::fread(input_snv, data.table = F)

# read pbta cohort
pbta <- readr::read_tsv(input_cohort_pbta, guess_max = 100000, show_col_types = FALSE)

## Read in genomic_df_filter file
genomic_df_filter <- readr::read_tsv(input_genomic_df_filter, guess_max = 100000, show_col_types = FALSE)
```


# Process Data: snv 

We need to process each input file and generate input files.
We will first change the column name of the biospecimen column to match the column name from the histologies files.

```{r process snv}
colnames(snv)[which(names(snv) == "Tumor_Sample_Barcode")] <- "Kids_First_Biospecimen_ID"
```  

```{r calculate VAF, echo=TRUE}
# using formula for VAF calculation
snv_vaf <- snv %>% mutate(VAF = t_alt_count / (t_ref_count + t_alt_count))
```

```{r echo=TRUE}
# we will subset to variables we will interested to focus on for downstream analysis
snv_vaf_subset <- subset(snv_vaf, 
                             select = c(Kids_First_Biospecimen_ID, Hugo_Symbol,Chromosome, Start_Position, Variant_Classification,VAF))
```

* TODO *
The following code is part of the module "tumor-clone-inference" and generates the "genomic_df_subset.tsv" file.
Maybe remove this part from here (or vice versa) so it's not duplicate in the repo.

```{r echo=TRUE}
# Merge genomic_df_filter with pbta_subset to get sample_id information
# Create match_id2 to count for multiple samples per patient, if any
genomic_df_filter_merge <- genomic_df_filter %>% 
  left_join(pbta, by=c('Kids_First_Participant_ID'))

genomic_df_subset <- genomic_df_filter_merge %>%
  subset(select = c(Kids_First_Participant_ID, Kids_First_Biospecimen_ID, sample_id, composition, match_id, tumor_descriptor, descriptors, cancer_group.x, experimental_strategy.y)) %>%
  filter(!(experimental_strategy.y == "RNA-Seq")) %>%
  mutate(match_id2 = paste(Kids_First_Participant_ID, sample_id, composition, sep = "_")) %>%
  mutate(tumor_descriptor = case_when(grepl("Primary Tumor", tumor_descriptor) ~ "Diagnosis",
                                 grepl("Initial CNS Tumor", tumor_descriptor) ~ "Diagnosis",
                                 grepl('Progressive Disease Post-Mortem', tumor_descriptor) ~ 'Deceased', 
                                 TRUE ~ tumor_descriptor)) %>%
  write_tsv(file.path(results_dir, "genomic_df_subset.tsv"))

genomic_df_subset %>%
  group_by(Kids_First_Participant_ID, match_id2, descriptors) %>%
  tally() %>%
  regulartable() %>%
  fontsize(size = 12, part = "all")
```


```{r echo=TRUE}
#maf_files <- snv_vaf_subset %>% 
#  left_join(genomic_df_subset, by=c('Kids_First_Biospecimen_ID')) %>%
#  filter(!is.na(Kids_First_Participant_ID))
  
# Create dir to save MAF files
#temp_path_csv <-
#  file.path(results_dir, "01_MAF_files_Per_Patient")
#if (!dir.exists(temp_path_csv)) {
#  dir.create(temp_path_csv)
#}

# we will change the dir here otherwise files are saved outside of the desired folder
#setwd(temp_path_csv)

# we will split masf data by the "Kids_First_Participant_ID.x" column
#maf_files %>% 
#  group_split(Kids_First_Participant_ID) %>% 
#  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))

# let's change back to the root_dir for the rest of the module
#setwd(root_dir)
```

# Autopsy samples 
We will focus on patient cases containing autopsy samples and save these maf files separately.

```{r echo=TRUE}
# Create dir to save MAF files separately for each patient case as well
scratch <-
  file.path(results_dir, "scratch")
if (!dir.exists(scratch)) {
  dir.create(scratch)
}

# we will change the dir here otherwise files are saved outside of the desired folder
setwd(scratch)

maf_files_Deceased <- snv_vaf_subset %>% 
  left_join(genomic_df_subset, by=c('Kids_First_Biospecimen_ID')) %>%
  filter(!is.na(Kids_First_Participant_ID)) %>%
  mutate(Deceased = case_when(grepl("Deceased", descriptors) ~ "Deceased")) %>%
  filter(Deceased == "Deceased") 

# Let us keep only VAF >= 0.1
maf_files_Deceased <- maf_files_Deceased[maf_files_Deceased$VAF>=0.5,] %>%
  write_tsv(file.path(scratch, "maf_files_Deceased.tsv"))
  
# we will split maf data by the "Kids_First_Participant_ID.x" column
maf_files_Deceased %>% 
  group_split(Kids_First_Participant_ID) %>% 
  walk(~write_csv(.x, paste0(.x$Kids_First_Participant_ID[1], "-vaf.csv")))

# let's change back to the root_dir for the rest of the module
setwd(root_dir)
```

## VAFs across all Matched Samples: Violin_plot

```{r Violin_plot}
# set the order for the x axis
maf_files_Deceased$tumor_descriptor <- factor(x = maf_files_Deceased$tumor_descriptor, levels = c("Diagnosis","Progressive", "Recurrence", "Deceased"))
#my_comparisons = list( c("Diagnosis","Progressive"), c("Diagnosis", "Recurrence"), c("Diagnosis", "Deceased"),
#                       c("Progressive", "Recurrence"), c("Progressive", "Deceased"),
#                       c("Recurrence", "Deceased"))

print(ggplot(maf_files_Deceased, aes(x= tumor_descriptor, y= VAF, fill = tumor_descriptor)) + 
  geom_violin() +
  #stat_compare_means(comparisons = my_comparisons, label.y = c(29, 35, 40))+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 55)  +   # Add global p-value
  stat_compare_means(method = "wilcox.test")+ # Add significance levels
  theme_Publication() +
  scale_y_continuous(limits=c(0.5,1))) +
  labs(title = "", x = "Time points", y = "VAF")

ggsave(filename = "Violin_plot_tumor_descriptor_Deceased.pdf", path = plots_dir,, width=7 ,height =5 ,device = "pdf")
```

## Mutations across all Matched Samples: Stacked_barplot

TODO - HOW TO COUNT #MUTATIONS PER POSITION???

```{r Stacked_barplot}
# count number of mutations per Kids_First_Participant_ID and tumor_descriptor
# tumor_descriptor <- c("Diagnosis","Progressive", "Recurrence", "Deceased")
counts <- ddply(maf_files_Deceased, .(maf_files_Deceased$Kids_First_Participant_ID, maf_files_Deceased$tumor_descriptor), nrow)
names(counts) <- c("Kids_First_Participant_ID", "tumor_descriptor", "Freq")

# set the order for the x axis
counts$tumor_descriptor <- factor(x = counts$tumor_descriptor, levels = c("Diagnosis","Progressive", "Recurrence", "Deceased"))

print(ggplot(counts, aes(x = factor(Kids_First_Participant_ID), y = Freq, fill = tumor_descriptor))+  
  geom_col(position = position_stack(reverse = TRUE)) +
  scale_fill_manual(values = c("gray", "pink", "firebrick3", "dodgerblue3")) +
  geom_bar( stat="identity", width = 0.9) + 
  theme_Publication() + 
  theme(axis.text.x = element_text(angle = 85, hjust = 1, vjust =1)) + 
#  scale_y_continuous(limits=c(0,1))) +
  labs(title = "", x = "Kids_First_Participant_ID", y = "Total Mutations"))

ggsave(filename = "Stacked_barplot_tumor_descriptor_Deceased.pdf", path = plots_dir,, width=10 ,height =6 ,device = "pdf")

# Remove PT_3CHB9PK5 for now because there are high number of mutations in there
# We will fix this once ensure we count number of mutations the right way

counts1 = counts %>%
  filter(!(Kids_First_Participant_ID == "PT_3CHB9PK5")) 

print(ggplot(counts1, aes(x = factor(Kids_First_Participant_ID), y = Freq, fill = tumor_descriptor))+  
  geom_col(position = position_stack(reverse = TRUE)) +
  scale_fill_manual(values = c("gray", "pink", "firebrick3", "dodgerblue3")) +
  geom_bar( stat="identity", width = 0.9) + 
  theme_Publication() + 
  theme(axis.text.x = element_text(angle = 85, hjust = 1, vjust =1)) + 
#  scale_y_continuous(limits=c(0,1))) +
  labs(title = "", x = "Kids_First_Participant_ID", y = "Total Mutations"))

ggsave(filename = "Stacked_barplot_tumor_descriptor_Deceased1.pdf", path = plots_dir,, width=10 ,height =6 ,device = "pdf")
```


## Corplots across all Matched Samples


```{r plot}
# Storing all Sample pairs in a list so each file can be processed iteratively
all_files <-  list.files(path = scratch, # Identify all CSV files
                       pattern = "*-vaf.csv", full.names = TRUE)
data_all <- read.csv(all_files[1])

for(i in 2:length(all_files)) {
  data_i <- read.csv(all_files[i])   # Reading files iteratively and storing in a dataframe
  data_i[is.na(data_i)] = 0  # Replace all na's with 0
}


for (i in all_files){
  
  d <- subset(data_i,
              select = c(Hugo_Symbol, VAF, tumor_descriptor)) 
  d <- dcast(d,Hugo_Symbol~tumor_descriptor)

  
  # Plotting scatterplot for all Diagnosis-Deceased Samples 
 
  p <- print(ggplot(d, aes(Diagnosis, Deceased, alpha = Hugo_Symbol)) +   # data_i$Recurrence, data_i$Deceased, 
    geom_point( size = 10,fill = 4, alpha = 1/6) + 
    scale_colour_manual(values = c("gray34", "dodgerblue3", "firebrick3")) + 
    #labs(title = paste(plot_title), x = axis_x, y = axis_y) + 
    geom_vline(xintercept = 0.1, linetype = "dashed") + # Adding vertical intercept
    geom_hline(yintercept = 0.1, linetype = "dashed") + # Adding horizontal intercept line
   # geom_text_repel(aes(label =ifelse(data_i$label > 0, paste("",data_i$Hugo_Symbol,""),'')),size = 3.5,hjust = 0,vjust = 0, nudge_x = 0.005,point.padding = NA,segment.color = NA, show.legend = FALSE, xlim = c(0.02,NA),ylim = c(0.025,0.96)) + # if label column is one, then label the point with gene name and it's corresponding Protein Change value
    theme_Publication() + 
    theme()+ 
    xlim(0,1) + 
    ylim(0,1))
  
  # Save as PDF
  ggsave(paste0(plots_dir,"-vaf.pdf"), p, width=8, height=6, device = "pdf")
  
}
```


```{r echo=TRUE}
# Delete Dir scratch because it contains large files not needed anymore
unlink(scratch,recursive = TRUE)
```


```{r echo=TRUE}
sessionInfo()
```
  